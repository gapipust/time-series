---
title: "Time Series Project"
author: "Natalia Pludra, Gasper Pust"
output:
  pdf_document: default
header-includes:
  - \usepackage{subfig}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
Sys.setlocale("LC_ALL", "English")
```

```{r message=FALSE, warning=FALSE}
library(xts)
library(forecast)
library(tseries)
library(astsa)
library(ggplot2)
library(dplyr)
library(knitr)
library(zoo)
library(tsbox)
library(latex2exp)
library(lubridate)
library(scales)
```


# Introduction

Forecasting real-world time series data is a fundamental theme in statistical modeling. This project focuses on analyzing and forecasting website traffic for an academic teaching notes website using robust statistical methods. The objective is to develop accurate models for predicting web traffic, leveraging patterns in the data. The report documents the full analytical process, including data preparation, model building, and validation.

# Dataset

This dataset contains daily time series data capturing various traffic metrics for a statistical forecasting teaching notes website (https://regressit.com/statforecasting.com/). The data was collected using StatCounter, a web traffic monitoring tool.

The dataset contains 2 167 rows of data from **September 14, 2014**, to **August 19, 2020** and includes daily counts of:

- **Page Loads:** Total pages accessed on the site.

- **Unique Visitors:** Distinct users visiting the site, identified by IP address.

- **First-Time Visitors:** Users accessing the site for the first time, identified by the absence of prior cookies.

- **Returning Visitors:** Users with prior visits, identified through cookies when accepted.

The data exhibits complex seasonality influenced by both the day of the week and the academic calendar.

The source of the data is Kaggle (https://www.kaggle.com/datasets/bobnau/daily-website-visitors).


```{r}
df_website <- read.csv("daily-website-visitors.csv")

df_website$Page.Loads <- as.numeric(gsub(",", ".", gsub("\\.", "", df_website$Page.Loads)))
df_website$Date <- as.Date(df_website$Date,format = "%m/%d/%Y")

kable(head(df_website,n=4), caption="Table1: Sample data")
```

We decided to focus on Daily Page Loads.

# Exploratory Data Analysis

The first step of the project was EDA. Figure 1 (a) shows our time series.

We divide the data into a training set and a test set. The test set will contain the last 6 months of observations.

CHANGE THE SIZE OF TRAINING AND TEST SET? 60 DAYS?

```{r fig.cap="Daily Page Loads", fig.subcap=c("The entire dataset", "Training set"), out.width='50%', out.height='50%'}
ts_website <- xts(df_website$Page.Loads, df_website$Date)

plot(ts_website, main = "Daily Page Loads", ylab = "Page Loads",lwd=1.2)

# Training set: First 4.5 years, Test set: Last 6 months
cutoff_date <- as.Date("2020-02-19")
train_data <- window(ts_website, end = cutoff_date)
test_data <- window(ts_website, start = cutoff_date + 1)

plot(train_data, main = "Daily Page Loads", ylab = "Page Loads", xlab = "Date",lwd=1.2)
```

The plot of the training set (Figure 1 (b)) does not indicate the presence of a trend or heteroscedasticity. However, there is evidence of cyclic patterns in the data. We can also notice unusual observations in 2017. The number of page loads was significantly lower than in other years.

Basic statistics and distribution of the Daily Page Loads are presented in Table 2 and Figure 2 (a).
There is no missing values in our data.

In the Figure 2 (b) we presented boxplots of Page Loads by day of the week.

```{r message=FALSE, warning=FALSE, fig.cap="Daily Page Loads Analysis", fig.subcap=c("Histogram of Daily Page Loads", "Boxplot of Page Loads by day of the week"), out.width='50%', out.height='50%'}
summary(df_website$Page.Loads)

ggplot(df_website, aes(Page.Loads)) +
  geom_histogram(fill="peachpuff3",color="black") +
  labs(x="Page Loads") +
  theme_minimal()

ggplot(df_website,aes(x=factor(Day,levels=c("Sunday", "Monday", "Tuesday", 
      "Wednesday", "Thursday", "Friday", "Saturday")),y=Page.Loads, group=Day)) +
  geom_boxplot(aes(fill=Day)) +
  labs(x="Day of the week", y="Page Loads") +
  theme_minimal() +
  theme(legend.position = "none")
```

We can observe that website traffic is lower during weekends.

We will check if the time series is stationary using Augmented Dickey-Fuller (ADF) test.

```{r}
adf.test(ts_website, alternative = "stationary")
```

Small p-value indicates that the time series is stationary (assuming significance level of 0.05).

Next, we proceed to compute the sample ACF and PACF for further analysis (Figure 3).

```{r fig.cap="ACF and PACF", fig.align='center', out.width='75%',out.height='75%'}
invisible(acf2(ts_website,max.lag= 80))
```

The seasonality feature are present in the sample ACF which shows cycles of 7 days - we have weekly seasonality.

```{r fig.cap="Correlation lag plots", fig.align='center', out.width='80%', out.height='80%'}
lag1.plot(ts_website,16,cex=0.5)
```

Looking at lag plots in Figure 4, we can see the strongest correlation at lag 1, 7 and 14.

# Seasonal Component and Modelling

As we observed in the previous part, there is a weekly seasonal component in our time series. We will try various types of differencing to remove this component.

```{r message=FALSE, warning=FALSE, fig.cap="Differenced data",fig.subcap=c("Page Loads over time", "ACF and PACF"), out.width='50%', out.height='50%'}
dlm1 <- diff(train_data,1)
plot(dlm1,lwd=1,main=expression(paste(Delta, "Page Loads train")))
invisible(acf2(dlm1,main=expression(paste(Delta, "Page Loads train"))))
```

```{r message=FALSE, warning=FALSE, fig.cap="Seasonally differenced data (period of 7 days)", fig.subcap=c("Page Loads over time", "ACF and PACF"), out.width='50%', out.height='50%'}
dlm7 <- diff(train_data,7)
plot(dlm7,lwd=1,,main=expression(paste(Delta[7], "Page Loads train")))
invisible(acf2(dlm7,main=expression(paste(Delta[7], "Page Loads train"))))
```

```{r message=FALSE, warning=FALSE, fig.cap="Differenced and seasonally differenced (period of 7 days) data",fig.subcap=c("Page Loads over time", "ACF and PACF"), out.width='50%', out.height='50%'}
dlm7.1 <- diff(diff(train_data,7),1)
plot(dlm7.1,lwd=1,main=expression(paste(Delta,Delta[7], "Page Loads train")))
invisible(acf2(dlm7.1,main=expression(paste(Delta,Delta[7], "Page Loads train"))))
```

Seasonally (with period of 7 days) and regularly differenced data in Figure 7, $\Delta_{7}\Delta Page Loads train$ seems more stationary. This implies a unit root $d=1$ as well as a seasonal unit root, $D=1.$ We can see that ACF decays to zero quicker than PACF indicating strong MA component of the model. ACF shows significant correlation at lags 7 and 14, which implies $q=3$ and $Q=2$. PACF shows significant correlation at lags 7, 14, 21, 28, 35, 42 and 49, which suggests $p=7$. 

We will try a set of models in order to find the optimal one: M1:$SARIMA(7,1,3)\times(0,1,2)_{7};$ M2:$SARIMA(6,1,3)\times(0,1,2)_{7};$ M3:$SARIMA(5,1,3)\times(0,1,2)_{7};$ M4:$SARIMA(5,1,2)\times(0,1,2)_{7};$ M5:$SARIMA(5,1,3)\times(1,1,2)_{7};$ M6:$SARIMA(5,1,3)\times(1,1,2)_{7};$. For each estimated model check adequacy by analyzing diagnostic on residuals and significance of estimated parameters.

```{r message=FALSE, warning=FALSE, results='hide', fig.align='center', out.width='75%', out.height='75%'}
visitors.fit1=sarima(train_data,7,1,3,0,1,2,7)

visitors.fit2=sarima(train_data,6,1,3,0,1,2,7)

visitors.fit3=sarima(train_data,5,1,3,0,1,2,7)

visitors.fit4=sarima(train_data,5,1,2,0,1,2,7)

visitors.fit5=sarima(train_data,5,1,3,1,1,2,7)

visitors.fit6=sarima(train_data,5,1,3,2,1,2,7)
```

COMMENTS ABOUT RESIDUALS - UNCORRELATED, GAUSSIAN DISTRIBUTION?

```{r message=FALSE, warning=FALSE, fig.align='center', out.width='75%', out.height='75%'}
visitors.fit1

visitors.fit2

visitors.fit3

visitors.fit4

visitors.fit5

visitors.fit6
```

COMMENT ABOUT ESTIMATED PARAMETERS SIGNIFICANCE

By comparing the AIC values of the selected models we can see that the model that provides the best fit is Model 5 $SARIMA(5,1,3)\times(1,1,2)_{7}$. We will do the forecasting with that model.

# Forecasting

**Forecasting 60-days ahead**

To forecast 60 steps ahead, we will use unique training data, which implies using a unique model fit.

**Forecasting 60 days with 1-step ahead - Interaction**

This forecasting strategy assumes we know the new data at the moment of the forecast, and we will not fit a new model based on new data. The forecast generation uses the fitted model to interact with new data to produce a forecast.

**Forecasting 60 days with 1-step ahead - Expanding windows**

In the expanding window strategy, the training sample size increases sequentially by a time unit. The forecasts produced are based on multiple fit models.

**Forecasting 60 days with 1-step ahead - Recursive windows**

In the recursive window strategy, the training sample maintains its size across the forecasting generation. However, with distinct sets of observation. The training sample window slides a time unit to produce a forecast. The forecasts produced are based on multiple fit models.

**Plotting of all forecasts**

```{r message=FALSE, warning=FALSE, fig.cap="Plot of different forecast methods", fig.align='center', out.width='75%', out.height='75%'}
ts_df <- data.frame(time = index(ts_website), value = coredata(ts_website))

# Forecasting 60-days ahead (unique model fit)
M5.fit_plots <- Arima(train_data, order=c(5,1,3), seasonal=list(order=c(1,1,2), period=7))

# Approach 1: Forecasting 60-days ahead
forecast_1 <- forecast(M5.fit_plots, h=60, level=95)
forecast_dates <- seq.Date(from = cutoff_date + days(1), by = "day", length.out = 60)
forecast_df_1 <- data.frame(Date = forecast_dates, Forecast = as.numeric(forecast_1$mean))

# Approach 2: Forecasting 60 days with 1-step ahead - Interaction
ts_df <- data.frame(time = index(ts_website), value = coredata(ts_website))
output_2 <- data.frame()

for (i in 0:59) {
  df_select <- ts_df %>% filter(time <= cutoff_date + days(i))
  ts_select <- ts(df_select$value, freq = 365, end = c(year(tail(df_select$time, 1)), 
    yday(tail(df_select$time, 1))))
  fit <- Arima(ts_select, model = M5.fit_plots)
  aux <- bind_cols(time = cutoff_date + days(i + 1), value = tail(fitted(fit), 1))
  output_2 <- bind_rows(output_2, aux)
}

forecast_ts_2 <- xts(output_2$value, order.by = output_2$time)
forecast_df_2 <- data.frame(Date = index(forecast_ts_2), 
                            Forecast = coredata(forecast_ts_2))

# Approach 3: Forecasting 60 days with 1-step ahead - Expanding windows
output_3 <- data.frame()
for (i in 0:59) {
  df_select <- ts_df %>% filter(time <= cutoff_date + days(i))
  ts_select <- ts(df_select$value, freq = 365, end = c(year(tail(df_select$time, 1)), 
    yday(tail(df_select$time, 1))))
  fit <- Arima(ts_select, order = c(5, 1, 3), seasonal = list(order = c(1, 1, 2), 
    period = 7))
  forecasted <- forecast(fit, h = 1, level = 95)
  aux <- data.frame(time = cutoff_date + days(i + 1), value = as.numeric(forecasted$mean))
  output_3 <- bind_rows(output_3, aux)
}

forecast_ts_3 <- xts(output_3$value, order.by = output_3$time)
forecast_df_3 <- data.frame(Date = index(forecast_ts_3), Forecast = coredata(forecast_ts_3))

# Approach 4: Forecasting 60 days with 1-step ahead - Recursive windows
output_4 <- data.frame()

for (i in 0:59) {
  start_date <- cutoff_date - months(3) + days(i)
  end_date <- cutoff_date + days(i)
  df_select <- ts_df %>% filter(time >= start_date & time <= end_date)
  ts_select <- ts(df_select$value, frequency = 365, start = c(year(start_date), 
    yday(start_date)))
  forecasted <- tryCatch({
    fit <- Arima(ts_select, order = c(5, 1, 3), seasonal = list(order = c(1, 1, 2), 
      period = 7))
    forecast(fit, h = 1, level = 95)
  }, error = function(e) {
    NULL # Return NULL if fitting fails
  })
  if (!is.null(forecasted)) {
    aux <- data.frame(time = end_date + days(1), value = as.numeric(forecasted$mean))
    output_4 <- bind_rows(output_4, aux)
  } else {
    aux <- data.frame(time = end_date + days(1), value = NA) # NA for failed forecasts
    output_4 <- bind_rows(output_4, aux)
  }
}

forecast_ts_4 <- xts(output_4$value, order.by = output_4$time)
forecast_df_4 <- data.frame(Date = index(forecast_ts_4), 
                            Forecast = coredata(forecast_ts_4))

# Combine observed, forecasts, and test data for plotting
test_df <- data.frame(Date = index(test_data), Observed = coredata(test_data))

# Plot for just the test data and forecasts (cutoff_date to last forecast)
last_forecast_date <- max(forecast_df_4$Date)

ts_df_filtered <- ts_df %>% filter(time <= last_forecast_date)
test_df_filtered <- test_df %>% filter(Date <= last_forecast_date)

# Plotting forecasts
ggplot() +
  geom_line(data = ts_df_filtered, aes(x = time, y = value, color = "Observed"), 
            size = 1, alpha = 0.8) +
  geom_line(data = forecast_df_1, aes(x = Date, y = Forecast, 
            color = "60-step ahead forecast"), size = 1) +
  geom_line(data = forecast_df_2, aes(x = Date, y = Forecast, 
            color = "1-step ahead forecast (Interaction)"), size = 1) +
  geom_line(data = forecast_df_3, aes(x = Date, y = Forecast, 
            color = "1-step ahead forecast (Expanding windows)"), size = 1) +
  geom_line(data = forecast_df_4, aes(x = Date, y = Forecast, 
            color = "1-step ahead forecast (Recursive windows)"), size = 1) +
  labs(title = "Forecasts from SARIMA Model for Daily Website Visitors", 
       x = "Date", y = "Page Loads") +
  scale_color_manual(values = c(
    "Observed" = "black",
    "60-step ahead forecast" = "darkred",
    "1-step ahead forecast (Interaction)" = "gold",
    "1-step ahead forecast (Expanding windows)" = "purple",
    "1-step ahead forecast (Recursive windows)" = "blue")) +
  theme_light() + theme(legend.title = element_blank(), 
    legend.background = element_blank(), legend.position = "bottom", 
    legend.direction = "vertical")

ggplot() +
  geom_line(data = test_df_filtered, aes(x = Date, y = Observed, color = "Observed"), 
            size = 1, linetype = "solid") +
  geom_line(data = forecast_df_1, aes(x = Date, y = Forecast, 
            color = "60-step ahead forecast"), 
            size = 1, linetype = "solid") +
  geom_line(data = forecast_df_2, aes(x = Date, y = Forecast, 
            color = "1-step ahead forecast (Interaction)"), 
            size = 1, linetype = "solid") +
  geom_line(data = forecast_df_3, aes(x = Date, y = Forecast, 
            color = "1-step ahead forecast (Expanding windows)"), 
            size = 1, linetype = "solid") +
  geom_line(data = forecast_df_4, aes(x = Date, y = Forecast, 
            color = "1-step ahead forecast (Recursive windows)"), 
            size = 1, linetype = "solid") +
  labs(title = "Forecasting Approaches from Cutoff Date to Last Forecast", 
       x = "Date", y = "Page Loads") +
    scale_color_manual(values = c(
    "Observed" = "black",
    "60-step ahead forecast" = "darkred",
    "1-step ahead forecast (Interaction)" = "gold",
    "1-step ahead forecast (Expanding windows)" = "purple",
    "1-step ahead forecast (Recursive windows)" = "blue")) +
  theme_light() + theme(legend.position = "bottom", 
    legend.direction = "vertical", legend.title = element_blank())
```

**Choosing the best approach**

```{r message=FALSE, warning=FALSE, fig.cap="Plot of forecast errors", fig.align='center', out.width='75%', out.height='75%'}
errors_1 <- test_df$Observed - forecast_df_1$Forecast
errors_2 <- test_df$Observed - forecast_df_2$Forecast
errors_3 <- test_df$Observed - forecast_df_3$Forecast
errors_4 <- test_df$Observed - forecast_df_4$Forecast

error_df <- data.frame(
  Date = test_df$Date,
  '60-step ahead forecast' = errors_1,
  '1-step ahead forecast (Interaction)' = errors_2,
  '1-step ahead forecast (Expanding windows)' = errors_3,
  '1-step ahead forecast (Recursive windows)' = errors_4)

error_df$Date <- as.Date(error_df$Date)

colnames(error_df) <- c(
  'Date',
  '60_step_ahead_forecast',
  '1_step_ahead_forecast_Interaction',
  '1_step_ahead_forecast_Expanding_windows',
  '1_step_ahead_forecast_Recursive_windows')

ggplot(error_df, aes(x = Date)) +
  geom_line(aes(y = `60_step_ahead_forecast`, 
            color = "60-step ahead forecast"), size = 1) +
  geom_line(aes(y = `1_step_ahead_forecast_Interaction`, 
            color = "1-step ahead forecast (Interaction)"), size = 1) +
  geom_line(aes(y = `1_step_ahead_forecast_Expanding_windows`, 
            color = "1-step ahead forecast (Expanding windows)"), size = 1) +
  geom_line(aes(y = `1_step_ahead_forecast_Recursive_windows`, 
            color = "1-step ahead forecast (Recursive windows)"), size = 1) +
  labs(title = "Forecasting Errors for Different Approaches", 
       x = "Date", y = "Forecast Error") +
    scale_color_manual(values = c(
    "60-step ahead forecast" = "darkred",
    "1-step ahead forecast (Interaction)" = "gold",
    "1-step ahead forecast (Expanding windows)" = "purple",
    "1-step ahead forecast (Recursive windows)" = "blue")) +
  theme_light() + theme(legend.title = element_blank(), 
      legend.background = element_blank(), legend.position = "bottom", 
      legend.direction = "vertical") +
  geom_hline(yintercept = 0, color = "black", size = 1)
```

95% PREDICTION INTERVALS 

```{r}
test_df_filtered <- head(test_df, 60)

accuracy <- rbind(
  accuracy(forecast_df_1$Forecast, test_df_filtered$Observed),
  accuracy(forecast_df_2$Forecast, test_df_filtered$Observed),
  accuracy(forecast_df_3$Forecast, test_df_filtered$Observed),
  accuracy(forecast_df_4$Forecast, test_df_filtered$Observed))

rownames(accuracy) <- c(
  '60-step ahead forecast',
  '1-step ahead forecast (Interaction)',
  '1-step ahead forecast (Expanding windows)',
  '1-step ahead forecast (Recursive windows)')

knitr::kable(accuracy, digits = 4, align = "ccccccc", 
  caption = "Accuracy measures for different forecasting approaches")
```

Based on accuracy measures in the table above, the best approach for forecasting is expanding windows.

# Analysis of Weekly Page Loads

Now, we are aggregating our data to weekly time series.

```{r fig.cap="Weekly Page Loads", fig.subcap=c("The entire dataset","The training dataset"), message=FALSE, warning=FALSE, out.width='50%', out.height='50%'}
ts_website_weekly <- apply.weekly(ts_website, mean)
plot(ts_website_weekly, main = "Weekly Average Page Loads", 
     ylab = "Page Loads", xlab = "Date")

# Training set: First 4.5 years, Test set: Last 6 months
cutoff_date <- as.Date("2020-02-19")
train_data_weekly <- window(ts_website_weekly, end = cutoff_date)
test_data_weekly <- window(ts_website_weekly, start = cutoff_date + 1)

plot(train_data_weekly, main = "Weekly Page Loads", ylab = "Page Loads", xlab = "Date")
```

We divide the data into a training set and a test set. The test set will contain the last 6 months of observations.


```{r fig.cap="ACF and PACF", fig.align='center', out.width='75%', out.height='75%'}
invisible(acf2(ts_website_weekly,max.lag= 80))
```

```{r}
adf.test(ts_website_weekly, alternative = "stationary")
```

Similar to the process before we try to find the best model for the weekly data. Here the seasonality seems yearly (period of 52 weeks). We try with the model $SARIMA(3,1,0)\times(1,1,1)_{52}$.

```{r message=FALSE, warning=FALSE, fig.cap="Differenced data", fig.subcap=c("Page Loads over time", "ACF and PACF"), out.width='50%', out.height='50%'}
dlm52.1 <- diff(diff(train_data_weekly,52),1)
plot(dlm52.1,lwd=1,main=expression(paste(Delta,Delta[52], "Weekly Page Loads train")))
invisible(acf2(dlm52.1,main=expression(paste(Delta,Delta[52], 
                                             "Weekly Page Loads train"))))
```

```{r message=FALSE, warning=FALSE, results='hide', fig.align='center', out.width='75%', out.height='75%'}
weekly_visitors.fit1=sarima(train_data_weekly,3,1,0,1,1,1,52)
```

```{r message=FALSE, warning=FALSE, fig.align='center', out.width='75%', out.height='75%'}
weekly_visitors.fit1
```


# Summary

BENEFITS AND LIMITATIONS OF THE MODELS
